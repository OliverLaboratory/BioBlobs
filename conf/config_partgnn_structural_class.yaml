hydra:
  run:
    dir: ./outputs/${train.wandb_project}/${data.dataset_name}/${data.split}/${now:%Y-%m-%d-%H-%M-%S}
  output_subdir: null

data: 
  dataset_name: structural_class  # Multi-class classification (SCOP)
  split: structure
  split_similarity_threshold: 0.7
  data_dir: /root/ICLR2026/partoken-protein/data
  test_mode: false  # Set to true for testing with limited data sizes (100 train, 20 val, 20 test)
  graph_eps: 10.0

model:
  # GNN model hyperparameters - optimized for multi-class
  embed_dim: 192   # Medium embedding size for multi-class
  num_layers: 3
  drop_rate: 0.1
  pooling: mean
  use_edge_attr: true
  edge_attr_dim: 1
  pe: learned
  
  # Partitioner hyperparameters - balanced for multi-class
  max_clusters: 6
  nhid: 50
  k_hop: 2
  cluster_size_max: 18
  termination_threshold: 0.95
  tau_init: 1.0
  tau_min: 0.1
  tau_decay: 0.95
  
  # Codebook hyperparameters
  codebook_size: 512
  codebook_dim: null
  codebook_beta: 0.25
  codebook_decay: 0.99
  codebook_eps: 1e-5
  codebook_distance: l2
  codebook_cosine_normalize: false
  
  # Loss weights - standard for multi-class
  lambda_vq: 1.0
  lambda_ent: 0.0
  lambda_psc: 1e-2
  lambda_card: 0.005
  psc_temp: 0.3

train:
  max_epochs: 120
  batch_size: 32
  learning_rate: 1e-3
  weight_decay: 1e-4
  num_workers: 4
  seed: 42
  
  # Scheduler settings
  use_cosine_schedule: true
  warmup_epochs: 10
  
  # Training settings
  early_stopping: true
  patience: 25     # Moderate patience for multi-class
  gradient_clip_val: 1.0
  log_every_n_steps: 50
  check_val_every_n_epoch: 1
  
  # Debug mode
  debug: false
  
  # Weights & Biases
  models_dir: ./saved_models
  wandb_project: partgnn_structural_class

# For W&B logging
use_wandb: false

# Interpretability settings
interpretability:
  enabled: true
  max_batches: 20